# 第1回ハンズオン：UNIXコマンドだけで構築するデータ処理パイプライン

**対応記事**: [第1回「2026年にUNIXを語る理由」](../../../series/unix-philosophy/ja/01-why-unix-now.md)

## 概要

フレームワークもライブラリも使わず、UNIXの標準コマンドだけでアクセスログの分析パイプラインを構築する。パイプ、リダイレクト、プロセス置換を使い、UNIX哲学の4本柱——単一責務、統一インタフェース、テキストストリーム、合成可能性——を体験する。

## 実行方法

```bash
# Docker上で実行（推奨）
docker run -it --rm ubuntu:24.04 bash

# コンテナ内でセットアップスクリプトを実行
# （スクリプトをコンテナにコピーするか、以下を直接実行）
bash setup.sh
```

または記事のハンズオンセクションに記載されたコマンドを順番に実行する。

## 学べること

1. パイプラインによるデータ処理——`cut`, `sort`, `uniq`, `awk` の組み合わせ
2. IPアドレス別アクセス数の集計
3. HTTPステータスコード別の分析
4. エラーリクエストの抽出とフィルタリング
5. プロセス置換（`<(...)`）による動的なファイル比較
6. 複合パイプラインによる総合レポート生成

## 動作環境

- Docker + ubuntu:24.04（推奨）
- または任意のLinux/macOS/WSL2環境
- 必要なコマンド: cat, grep, sort, uniq, wc, cut, tr, sed, awk, head, tail, diff（すべて標準インストール済み）
