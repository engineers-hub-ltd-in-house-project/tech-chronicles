#!/bin/bash
set -euo pipefail

WORKDIR="${HOME}/command-line-handson-23"

echo "========================================"
echo " 第23回ハンズオン: コマンドラインの本質に立ち返る"
echo " テキスト・組み合わせ・自動化"
echo "========================================"
echo ""
echo "作業ディレクトリ: ${WORKDIR}"
mkdir -p "${WORKDIR}"
cd "${WORKDIR}"

# ========================================
# テスト用データの生成
# ========================================
echo ""
echo "--- テスト用データを生成中 ---"

cat > "${WORKDIR}/access.log" << 'LOGEOF'
2025-01-15 10:00:01 GET /api/users 200 45ms
2025-01-15 10:00:02 POST /api/users 201 120ms
2025-01-15 10:00:03 GET /api/products 200 30ms
2025-01-15 10:00:04 GET /api/users/1 404 5ms
2025-01-15 10:00:05 GET /api/products 200 28ms
2025-01-15 10:00:06 DELETE /api/users/1 500 200ms
2025-01-15 10:00:07 GET /api/products 200 32ms
2025-01-15 10:00:08 GET /api/users 200 42ms
2025-01-15 10:00:09 POST /api/orders 201 150ms
2025-01-15 10:00:10 GET /api/orders/1 404 4ms
2025-01-15 10:00:11 GET /api/products/5 200 25ms
2025-01-15 10:00:12 PUT /api/users/2 200 80ms
2025-01-15 10:00:13 GET /api/health 200 2ms
2025-01-15 10:00:14 GET /api/users/99 404 3ms
2025-01-15 10:00:15 POST /api/products 500 300ms
LOGEOF

echo "  access.log を生成しました（15行）"

# ========================================
# 演習1: テキストストリームの普遍性
# ========================================
echo ""
echo "========================================"
echo " 演習1: テキストストリームの普遍性"
echo "========================================"
echo ""

echo "--- 1973年のツールでログを分析する ---"
echo ""

echo "grepでエラー（4xx/5xx）を抽出:"
grep -E ' [45][0-9]{2} ' "${WORKDIR}/access.log"
echo ""

echo "awkでURLとステータスコードだけを抽出:"
awk '{print $4, $5}' "${WORKDIR}/access.log"
echo ""

echo "grep + awk + sort + uniq -c でエラーURLを集計:"
grep -E ' [45][0-9]{2} ' "${WORKDIR}/access.log" \
  | awk '{print $4}' \
  | sort \
  | uniq -c \
  | sort -rn
echo ""

echo "[解説]"
echo "  grep（1973年）、awk（1977年）、sort/uniq（1970年代）が"
echo "  2025年に書かれたログをそのまま処理できる。"
echo "  テキストストリームというインターフェースが"
echo "  50年間変わっていないからだ。"

# ========================================
# 演習2: 組み合わせの力
# ========================================
echo ""
echo "========================================"
echo " 演習2: 組み合わせの力"
echo "========================================"
echo ""

echo "--- 同じデータに対して異なるパイプラインを組む ---"
echo ""

echo "パイプライン1: HTTPメソッド別のリクエスト数"
awk '{print $3}' "${WORKDIR}/access.log" \
  | sort | uniq -c | sort -rn
echo ""

echo "パイプライン2: 応答時間が100msを超えるリクエスト"
awk '{
  gsub(/ms/, "", $6);
  if ($6+0 > 100) print $0
}' "${WORKDIR}/access.log"
echo ""

echo "パイプライン3: 時間帯別のリクエスト数（秒単位）"
awk '{print substr($2,1,7)}' "${WORKDIR}/access.log" \
  | sort | uniq -c
echo ""

echo "[解説]"
echo "  同じ入力データ（access.log）に対して、"
echo "  パイプラインを組み替えるだけで異なる分析ができる。"
echo "  各コマンドは入力がどこから来たか知らない。"
echo "  出力がどこに行くかも知らない。"
echo "  この「無関心」こそが合成可能性の源泉だ。"

# ========================================
# 演習3: 自動化の実践
# ========================================
echo ""
echo "========================================"
echo " 演習3: 手動操作をスクリプトに変換する"
echo "========================================"
echo ""

echo "--- 分析スクリプトを自動生成 ---"

cat > "${WORKDIR}/analyze.sh" << 'SCRIPT'
#!/bin/bash
set -euo pipefail

LOG_DIR="${1:-.}"
echo "=== ログ分析レポート ==="
echo "対象ディレクトリ: ${LOG_DIR}"
echo "実行日時: $(date)"
echo ""

echo "--- ファイル一覧と行数 ---"
find "${LOG_DIR}" -name "*.log" -exec wc -l {} +
echo ""

echo "--- ステータスコード別集計 ---"
for code in 200 201 404 500; do
    count=$(grep -c " ${code} " "${LOG_DIR}"/*.log 2>/dev/null || echo "0")
    echo "  HTTP ${code}: ${count} 件"
done
echo ""

echo "--- エラーリクエスト詳細（4xx/5xx） ---"
grep -E ' [45][0-9]{2} ' "${LOG_DIR}"/*.log 2>/dev/null || echo "  エラーなし"
echo ""

echo "--- 応答時間の統計 ---"
awk '{
  gsub(/ms/, "", $6);
  sum += $6; count++;
  if ($6+0 > max) max = $6
}
END {
  if (count > 0)
    printf "  平均: %.1fms  最大: %dms  リクエスト数: %d\n", sum/count, max, count
}' "${LOG_DIR}"/*.log

echo ""
echo "=== レポート終了 ==="
SCRIPT

chmod +x "${WORKDIR}/analyze.sh"

echo "生成されたスクリプト: ${WORKDIR}/analyze.sh"
echo ""
echo "--- スクリプトを実行 ---"
echo ""
bash "${WORKDIR}/analyze.sh" "${WORKDIR}"
echo ""

echo "[解説]"
echo "  ターミナルで手動実行したコマンドが"
echo "  そのままスクリプトになった。"
echo "  テキストで操作し（テキストの原則）、"
echo "  コマンドを組み合わせ（組み合わせの原則）、"
echo "  スクリプトとして記録した（自動化の原則）。"
echo "  三つの原則が一つのワークフローに凝縮されている。"

# ========================================
# 演習4: ワークフロー棚卸し
# ========================================
echo ""
echo "========================================"
echo " 演習4: ワークフロー棚卸しワークシート"
echo "========================================"
echo ""

cat << 'WORKSHEET'
以下の表を自分の日常のCLIワークフローで埋めてみよう。

+-------------------+----------+----------+----------+
| 日常のタスク       |テキスト  |組み合わせ|自動化    |
|                   |活用度    |活用度    |活用度    |
+-------------------+----------+----------+----------+
| 例: ログ分析       | (◎)     | (◎)     | (△)     |
|   grep+awkで都度   |テキスト  |パイプ   |毎回手動  |
|   手動実行         |ログ直接 |ライン   |で打つ    |
|                   |参照     |駆使     |         |
+-------------------+----------+----------+----------+
| 例: デプロイ       | (◎)     | (◎)     | (◎)     |
|   CI/CDパイプライン |YAML/    |ステップ |自動実行  |
|                   |テキスト |連結     |         |
+-------------------+----------+----------+----------+
| あなたのタスク1:    |          |          |          |
|                   |          |          |          |
+-------------------+----------+----------+----------+
| あなたのタスク2:    |          |          |          |
|                   |          |          |          |
+-------------------+----------+----------+----------+

評価基準:
  (◎) = 原則を十分に活かしている
  (○) = 部分的に活かしている
  (△) = ほとんど活かしていない
  (×) = まったく活かしていない

改善のヒント:
  テキスト(△) → 出力をJSON/テキストに変換するオプションがないか確認
  組み合わせ(△) → パイプラインで他のツールと繋げられないか検討
  自動化(△) → 繰り返し実行しているなら、スクリプト化を検討
WORKSHEET

echo ""
echo "[解説]"
echo "  自分のワークフローを三つの軸で分析すると、"
echo "  どの原則を活かし、どの原則を無視しているかが見える。"
echo "  無視している原則を意識的に取り入れることが、"
echo "  CLIワークフローの改善につながる。"

# ========================================
# 完了
# ========================================
echo ""
echo "========================================"
echo " 全演習完了"
echo "========================================"
echo ""
echo "作業ディレクトリ: ${WORKDIR}"
echo ""
echo "クリーンアップ:"
echo "  rm -rf ${WORKDIR}"
