# データベースの地層

## ——RDBからNewSQLまで、データ管理50年の地殻変動

### 第24回：データベースの地層を読む——あなたは何を選ぶか

**連載「データベースの地層——RDBからNewSQLまで、データ管理50年の地殻変動」**
**著：佐藤裕介（Engineers Hub株式会社 CEO / Technical Lead）**

---

**この回で学べること：**

- 全23回の連載を貫く「データベース技術50年の地層」の全体像
- データベース選定のための6つの判断軸——データの性質、アクセスパターン、一貫性要件、スケール要件、運用体制、エコシステム
- 各判断軸に沿った具体的なデータベース特性のマッピング
- 2020年代のデータベース技術の潮流——PostgreSQLの覇権、サーバレス化、AI時代のデータ管理
- 「銀の弾丸は存在しない」ことを受け入れた上での、実践的な技術選定フレームワーク
- 自分のプロジェクトに最適なデータベースを選定するための評価マトリクスの作り方

---

## 1. 24年分の地層を前にして

この連載を書き始めたとき、私は一つの不安を抱えていた。

24回にわたってデータベースの歴史を語り終えたとき、読者の手元に何が残るのか。ファイルベースのデータ管理の限界、階層型データベースのツリー構造、Coddのリレーショナルモデル、SQLの宣言的美しさ、ACID特性の数学的厳密さ、MySQLとPostgreSQLの設計思想の違い、NoSQLの衝撃、CAP定理のトレードオフ、NewSQLの野心、ベクトルDBの可能性——これらの知識が、単なる「教養」で終わるのではないかという不安だ。

歴史を知ることは手段であって目的ではない。

2025年のある日、若手エンジニアからSlackでメッセージが届いた。「新規プロジェクトのデータベースを選定しているのですが、PostgreSQLとMySQLとDynamoDBとMongoDBで迷っています。どれがいいですか？」

私は返信の手を止めた。「どれがいい」という問いに、一般的な正解はない。だが問い方を変えれば、判断基準は存在する。

「そのプロジェクトのデータは、どんな構造をしている？ 読み取りと書き込みの比率は？ 一貫性はどこまで必要？ スケールはどの程度を見込んでいる？ 運用は誰がやる？」

私がそう返したとき、相手は少し考えてから「そういう軸で考えたことがなかったです」と答えた。

この連載の目的は、まさにそこにある。データベースの歴史を知ることで、「そういう軸」を手に入れること。技術選定を「なんとなく」や「フレームワークのデフォルト」ではなく、「判断基準に基づく選択」に変えること。

最終回となるこの回では、全23回で辿ってきた50年分の地層を一枚の地図に描き直す。そしてその地図を使って、あなたのプロジェクトに最適なデータベースを「選ぶ」ためのフレームワークを提示する。

---

## 2. 50年の地層——全23回の全体像

### データベース技術の地質年代

全23回で辿ってきたデータベース技術の歴史を、地質学の年代区分になぞらえて整理する。各時代は前の時代の「問題」を解決するために生まれ、同時に新しい「問題」を生み出した。この連鎖を理解することが、技術選定の基盤となる。

```
データベース技術の地質年代表

先カンブリア時代 (1950-1960年代) ── ファイルベースのデータ管理
│  第1回: なぜデータベースの歴史を学ぶのか
│  第2回: ファイルからデータベースへ
│  解決した問題: データの永続化
│  残った問題:  冗長性、不整合、並行アクセス不能
│
古生代 (1960-1970年代) ── 階層型・ネットワーク型データベース
│  第3回: 階層型とネットワーク型
│  解決した問題: 構造化されたデータ管理、並行アクセス
│  残った問題:  物理構造への依存、柔軟性の欠如
│
中生代 (1970-1990年代) ── リレーショナルデータベースの支配
│  第4回:  Coddの革命
│  第5回:  SQLの誕生
│  第6回:  Oracle, DB2, PostgreSQL
│  第7回:  ACIDとトランザクション
│  第8回:  MySQL vs PostgreSQL
│  第9回:  ストアドプロシージャとトリガー
│  第10回: インデックス設計
│  第11回: レプリケーションとシャーディング
│  解決した問題: 論理的データ独立性、宣言的クエリ、ACID保証
│  残った問題:  水平スケーリングの限界、柔軟なスキーマへの対応
│
新生代前期 (2000-2010年代) ── NoSQL革命
│  第12回: CAP定理
│  第13回: Memcached, Redis
│  第14回: MongoDB, CouchDB
│  第15回: Cassandra, DynamoDB
│  第16回: 時系列DB, グラフDB
│  解決した問題: 水平スケーリング、柔軟なデータモデル、高可用性
│  残った問題:  一貫性の犠牲、SQLの喪失、運用の複雑化
│
新生代後期 (2010年代-現在) ── NewSQL・サーバレス・AI時代
│  第17回: Google Spanner
│  第18回: CockroachDB, TiDB
│  第19回: サーバレスDB
│  第20回: ベクトルDBとAI時代
│  第21回: データレイクとLakehouse
│  第22回: SQLの不死
│  第23回: データモデリングの本質
│  解決した問題: 分散+強一貫性の両立、運用負荷の軽減、AI統合
│  残った問題:  コスト予測、ベンダーロックイン、複雑性の増大
```

### 各時代が教えてくれること

この年代表を眺めると、一つの明確なパターンが浮かび上がる。

**すべてのデータベース技術は、先行する技術の「限界」に対する回答として生まれた。** ファイルベースの限界がDBMSを生み、階層型の柔軟性欠如がリレーショナルモデルを生み、RDBのスケーリング限界がNoSQLを生み、NoSQLの一貫性欠如がNewSQLを生んだ。

だが同時に、**「完全な代替」は一度も実現していない。** NoSQLはRDBを殺さなかった。NewSQLはNoSQLを殺さなかった。サーバレスDBはオンプレミスのDBを殺さなかった。各技術は「共存」している。2026年2月のDB-Engines Rankingで上位を占めるのは、依然としてOracle、MySQL、SQL Server、PostgreSQLというリレーショナルデータベースだ。一方でMongoDB、Redis、Elasticsearch、Cassandraも確固たる地位を維持している。

この共存の事実が、技術選定の本質を物語る。「最新の技術が最良」ではない。「古い技術は劣る」でもない。各技術は異なるトレードオフの上に成り立っており、プロジェクトの要件に最も適合するトレードオフを選ぶことが、技術選定の核心だ。

### 2020年代の潮流——連載を通じて見えてきたもの

全23回を書き終えて、2020年代のデータベース技術に三つの大きな潮流が見える。

**第一に、PostgreSQLの覇権。** Stack Overflow Developer Survey 2025では、PostgreSQLがプロフェッショナル開発者の55.6%に利用され、3年連続で「最も賞賛されるデータベース」の座を維持している。第8回で語ったように、かつてMySQLの「手軽さ」に敗れたPostgreSQLが、拡張性と標準準拠という設計哲学の強みを武器に逆転した。pgvectorによるベクトル検索対応（第20回）、TimescaleDBによる時系列データ対応（第16回）、PostGISによる地理空間データ対応——PostgreSQLは「拡張で何にでもなれるデータベース」として、事実上のデフォルト選択肢になりつつある。

**第二に、サーバレス化とマネージド化の加速。** 第19回で語ったNeon、PlanetScale、Tursoといったサーバレスデータベースの台頭は、データベース運用の概念自体を変えつつある。2025年にDatabricksがNeonを買収した事実は、サーバレスPostgreSQLがデータプラットフォーム全体の戦略的ピースになったことを示している。第21回で語ったDuckDBの台頭も、「データベースサーバを立てずに分析する」という新しいパラダイムを象徴する。

**第三に、データベースの境界の曖昧化。** 第22回で語ったように、SQLはあらゆる場所に回帰した。RDBがJSONBでドキュメント指向の機能を取り込み、pgvectorでベクトル検索を取り込み、DuckDBでOLAP機能を補完する。逆にMongoDBはトランザクションをサポートし（v4.0、2018年）、Redisはデータ構造サーバとしてRDBの一部機能を代替する。「RDB vs NoSQL」という二項対立は、もはや意味を持たない。各データベースが他の領域に越境し、ポリグロット（多言語）な構成が当たり前になった。

---

## 3. データベース選定の6つの判断軸

50年の歴史が教えてくれるのは、データベース選定に万能の回答はないということだ。だが「判断基準」は存在する。全23回を通じて見えてきた判断軸を、6つに整理する。

### 軸1: データの性質

最初に問うべきは「データの性質は何か」だ。

第2回で見たように、データベースの根源的な存在理由は「データの構造化と管理」にある。だがデータの性質によって、最適な構造化の方法は異なる。

```
データの性質による分類

構造化データ (Structured)
  定義: 明確なスキーマを持つ。行と列で表現できる
  例:   顧客情報、注文データ、会計データ
  適合: RDB (PostgreSQL, MySQL, Oracle)
        NewSQL (CockroachDB, TiDB, Spanner)

半構造化データ (Semi-structured)
  定義: 柔軟なスキーマ。JSONやXMLで表現される
  例:   ログデータ、設定情報、APIレスポンス
  適合: ドキュメントDB (MongoDB, CouchDB)
        RDB + JSONB (PostgreSQL)

非構造化データ (Unstructured)
  定義: 固定のスキーマを持たない
  例:   テキスト、画像、音声のメタデータとEmbedding
  適合: ベクトルDB (Pinecone, Weaviate, pgvector)
        全文検索エンジン (Elasticsearch)

時系列データ (Time-series)
  定義: タイムスタンプと値のペア。追記が支配的
  例:   IoTセンサーデータ、メトリクス、株価
  適合: 時系列DB (InfluxDB, TimescaleDB, Prometheus)

グラフデータ (Graph)
  定義: ノード（エンティティ）とエッジ（関係）
  例:   ソーシャルネットワーク、推薦システム、知識グラフ
  適合: グラフDB (Neo4j, Amazon Neptune)
        RDB + 再帰CTE (小規模なら)
```

第16回で語ったように、「汎用データベースでは足りない」用途が専用DBを生み出した。だが同時に、PostgreSQLの拡張性が「専用DBを使わなくても済む」ケースを増やしている。pgvector、TimescaleDB、Apache AGE（グラフ拡張）——PostgreSQLの拡張エコシステムは、データの性質が複合的な場合に特に有効だ。

判断のポイントは「データの性質が単一か複合か」にある。単一の性質が支配的なら専用DBの方が効率的だ。複数の性質が混在するなら、PostgreSQL + 拡張の方が運用の複雑さを抑えられる。

### 軸2: アクセスパターン

第23回で詳しく語ったように、正規化は「書き込み最適化」、非正規化は「読み取り最適化」の設計手法だ。だがデータモデルの設計だけでなく、データベース自体の選択もアクセスパターンに依存する。

```
アクセスパターンによる分類

OLTP (Online Transaction Processing)
  特徴: 短い個別トランザクション。行単位の読み書き
  例:   Webアプリケーション、ECサイト、銀行システム
  適合: RDB (PostgreSQL, MySQL)
        NewSQL (CockroachDB, TiDB)
  理由: ACID保証、行指向ストレージ、インデックスの効率

OLAP (Online Analytical Processing)
  特徴: 大量データの集約・分析。列単位の読み取り
  例:   BI、レポーティング、データサイエンス
  適合: 列指向DB (ClickHouse, BigQuery)
        DuckDB (小〜中規模)
        データウェアハウス (Snowflake, Redshift)
  理由: 列指向ストレージ、ベクトル化実行、圧縮効率

HTAP (Hybrid Transactional/Analytical Processing)
  特徴: OLTPとOLAPの両方を単一システムで
  例:   リアルタイム分析、運用分析
  適合: TiDB (TiFlash)、AlloyDB、SingleStore
  理由: 行指向+列指向の二重ストレージ

キーバリュー / キャッシュ
  特徴: キーによる高速な読み書き。シンプルなデータモデル
  例:   セッション管理、キャッシュ、リアルタイムカウンター
  適合: Redis/Valkey、Memcached、DynamoDB
  理由: メモリ常駐、O(1)アクセス

全文検索
  特徴: テキストの高速検索。転置インデックス
  例:   検索エンジン、ログ分析
  適合: Elasticsearch、Meilisearch
        PostgreSQL (tsvector)
  理由: 転置インデックス、形態素解析、ランキング
```

第10回で語ったインデックス設計の知識がここで活きる。データベースの「速さの正体」は、データの物理的な配置とアクセスパターンの整合にある。OLTPワークロードに列指向データベースを使えば性能は出ない。OLAPワークロードに行指向データベースを使えば、大規模な集約クエリで苦しむ。

### 軸3: 一貫性要件

第7回のACID特性と第12回のCAP定理——この連載の核心的テーマの一つだ。

```
一貫性要件のスペクトラム

強一貫性 (Strong Consistency)
  ───────────────────────────────────────
  │  読み取りは常に最新の書き込みを反映する
  │
  │  適合するシステム:
  │  ├ 金融取引（口座残高、送金）
  │  ├ 在庫管理（在庫数の正確性）
  │  ├ 予約システム（二重予約の防止）
  │  └ マスターデータ管理
  │
  │  適合するDB:
  │  ├ PostgreSQL, MySQL (単一ノード)
  │  ├ Google Cloud Spanner (分散)
  │  └ CockroachDB, TiDB (分散)
  │
  │  代償: レイテンシの増加、スループットの制限
  ───────────────────────────────────────

結果整合性 (Eventual Consistency)
  ───────────────────────────────────────
  │  書き込みはいずれ全ノードに伝播する
  │  一時的に古いデータが読まれる可能性がある
  │
  │  適合するシステム:
  │  ├ ソーシャルメディアのフィード
  │  ├ 「いいね」カウンター
  │  ├ レコメンデーション
  │  └ ログ・メトリクス収集
  │
  │  適合するDB:
  │  ├ Cassandra, DynamoDB
  │  ├ MongoDB (デフォルト設定)
  │  └ Redis (レプリケーション構成)
  │
  │  利点: 高可用性、低レイテンシ、水平スケーリング
  ───────────────────────────────────────
```

第12回で語ったように、CAP定理の本質は「選べ」ということだ。ネットワーク分断は避けられない以上、一貫性と可用性のどちらを優先するかを選ばなければならない。だが多くのプロジェクトでは、システム全体が均一に強一貫性を必要とするわけではない。

実務的なアプローチは、システム内の各ドメインごとに一貫性要件を定義することだ。金融取引のコア処理には強一貫性を、分析用のレプリカには結果整合性を、キャッシュ層にはTTLベースの整合性を——同じシステム内でも異なる一貫性レベルを使い分ける。第23回で語ったDDDの境界づけられたコンテキストの考え方が、ここでも有効に機能する。

### 軸4: スケール要件

第11回で語ったレプリケーションとシャーディングの知識が、この軸の判断基盤となる。

```
スケール要件による分類

単一ノードで十分
  データ量:   〜数百GB
  同時接続:   〜数百
  書き込み:   〜数千TPS
  ───────────────────────────────
  PostgreSQL, MySQL で十分
  「スケールしない」のではなく
  「スケールする必要がない」
  多くのプロジェクトはここに収まる

垂直スケール (スケールアップ)
  データ量:   数百GB〜数TB
  同時接続:   数百〜数千
  書き込み:   数千〜数万TPS
  ───────────────────────────────
  高性能なサーバ + PostgreSQL/MySQL
  Amazon RDS, Cloud SQL
  リードレプリカで読み取りを分散
  まだシャーディングは不要

水平スケール (スケールアウト)
  データ量:   数TB〜数PB
  同時接続:   数万以上
  書き込み:   数万TPS以上
  ───────────────────────────────
  NewSQL: CockroachDB, TiDB, Spanner
  NoSQL:  Cassandra, DynamoDB
  シャーディング or 分散アーキテクチャ
```

第17回と第18回で語ったように、NewSQL（CockroachDB、TiDB、Spanner）は「RDBの操作性 + 分散のスケーラビリティ」を目指している。だがその代償——レイテンシの増加、運用の複雑さ、コスト——は消えていない。

私が24年間の経験で学んだ最も重要な教訓の一つは、「多くのプロジェクトは、想像するほどスケールしない」ということだ。水平スケールが必要になるのは、全プロジェクトのごく一部だ。単一ノードのPostgreSQLは、適切なインデックス設計（第10回）とクエリ最適化があれば、数百GBのデータと数百の同時接続を十分にさばける。

「いつかスケールが必要になるかもしれない」という推測で分散データベースを選ぶのは、多くの場合、過剰設計だ。YAGNI（You Aren't Gonna Need It）の原則は、データベース選定にも適用される。

### 軸5: 運用体制

第19回で語ったサーバレスDBの文脈で浮き彫りになったのは、データベースの選択が技術的な判断だけでなく、組織的な判断でもあるということだ。

```
運用体制による分類

自前運用 (Self-managed)
  ──────────────────────────────────────
  前提: DBA（データベース管理者）がいる
        インフラチームがある
  メリット: 最大限のカスタマイズ性
            コスト予測が容易
            ベンダーロックインなし
  デメリット: 人的コストが高い
             バックアップ、監視、パッチ適用が自己責任
  適合: 大規模組織、特殊な要件があるシステム

マネージド (Managed)
  ──────────────────────────────────────
  前提: クラウドを利用している
  メリット: バックアップ、監視、パッチが自動化
            スケーリングが容易
  デメリット: カスタマイズの制限
             コストが変動する
             ベンダーロックインのリスク
  例: Amazon RDS, Cloud SQL, Azure Database
  適合: ほとんどの企業のほとんどのプロジェクト

サーバレス (Serverless)
  ──────────────────────────────────────
  前提: 運用負荷を最小化したい
  メリット: 運用負荷がほぼゼロ
            使った分だけ課金
            ゼロスケール可能
  デメリット: コールドスタート
             コスト予測の難しさ
             機能の制限
  例: Neon, PlanetScale, Turso, D1
  適合: スタートアップ、個人開発、変動負荷
```

運用体制の選択は、チームの構成と成熟度に依存する。5人のスタートアップがPostgreSQLを自前運用するのは、技術的には可能だが組織的には非合理だ。逆に、1000人のエンジニア組織がすべてをサーバレスDBに載せるのは、コスト管理の観点で問題が生じうる。

2024年から2025年にかけて、OSSデータベースのライセンス変更が相次いだことも、運用体制の判断に影響する。Redisが2024年3月にBSDライセンスからSSPL/RSALに変更し、Linux FoundationがValkey forkを立ち上げた。CockroachDBは2024年にEnterprise Licenseに移行し、OSS版のCore Free Editionを終了した。OSSデータベースを自前運用する場合、ライセンスの持続可能性も考慮すべき要素となった。

### 軸6: エコシステムと人的資本

最後の軸は、しばしば見落とされるが極めて重要な要素だ。

第22回で語ったSQLの不死の理由の一つは、「SQLを書ける人間の数」という人的資本だった。技術選定は真空の中で行われるのではない。チームのスキルセット、採用市場、ライブラリやツールの充実度、コミュニティの活性度——これらのエコシステム要因が、技術的な優劣を覆すことがある。

第8回で語ったように、MySQLがWeb時代を制覇した理由は技術的な優位性ではなく「手軽さ」だった。LAMPスタックの一部として世界中のホスティング環境にプリインストールされていたこと、phpMyAdminで誰でも触れたこと——エコシステムの力がMySQLを勝者にした。

2026年現在、PostgreSQLのエコシステムは急速に拡大している。Stack Overflow Developer Survey 2025でプロフェッショナル開発者の55.6%が利用するという数字は、採用市場でPostgreSQL経験者を見つけやすいことを意味する。Prisma、Drizzle、SQLAlchemy、ActiveRecordといったORMがPostgreSQLを第一級でサポートしていること、pgvector、TimescaleDB、PostGISといった拡張が充実していることも、エコシステムの強みだ。

だがエコシステムの判断は、グローバルなトレンドだけでなくローカルな文脈にも依存する。チームに3人のMongoDB熟練者がいるなら、PostgreSQLに移行する技術的な理由があっても、移行コストとの天秤を考えるべきだ。

---

## 4. ハンズオン: データベース選定の評価マトリクスを作る

理論を語るだけでは足りない。自分のプロジェクトに最適なデータベースを「選ぶ」ための、実践的なツールを提供する。

### 評価マトリクスの設計

6つの判断軸を使って、複数のデータベース候補を定量的に比較する。完璧な定量化は不可能だが、「なんとなく」の選定を「根拠のある選定」に変える効果がある。

### 環境構築

```bash
# handson/database-history/24-reading-database-strata/setup.sh を実行
bash setup.sh
```

### 演習1: 要件定義テンプレート

まずプロジェクトの要件を明確化する。

```bash
# 要件定義テンプレートを作成し、記入する
cat << 'EOF'
============================================================
データベース選定 要件定義シート
============================================================

[1. データの性質]
  主要なデータ型:     ___________________
  スキーマの変更頻度: 低 / 中 / 高
  データ間の関連性:   単純 / 中程度 / 複雑

[2. アクセスパターン]
  読み取り:書き込み比率: ___:___
  主要な操作:           CRUD / 集計 / 検索 / 時系列
  レイテンシ要件:       <10ms / <100ms / <1s / 許容

[3. 一貫性要件]
  トランザクション:     必須 / 部分的 / 不要
  一貫性レベル:         強一貫性 / 結果整合性 / 混合

[4. スケール要件]
  初期データ量:         ___GB
  1年後の予測:          ___GB
  同時接続数:           ___
  書き込みTPS:          ___

[5. 運用体制]
  DBAの有無:           いる / いない
  クラウド利用:         AWS / GCP / Azure / オンプレ
  運用予算:            月額 ___円

[6. エコシステム]
  チームのスキル:      ___________________
  既存のインフラ:      ___________________
  採用市場の制約:      ___________________
============================================================
EOF
```

### 演習2: スコアリング

要件に基づいて、各候補データベースを1-5点でスコアリングする。

```bash
cat << 'EOF'
============================================================
データベース選定 スコアリングマトリクス
============================================================

評価基準: 1(不適合) - 5(最適)

例: ECサイトの注文管理システム
  - 構造化データ中心、読み取り:書き込み = 7:3
  - 強一貫性必須（在庫管理）
  - 初期10GB、1年後100GB
  - DBAなし、AWS利用
  - チームはPostgreSQL経験あり

                  PostgreSQL  MySQL  DynamoDB  MongoDB
                  (RDS)       (RDS)
──────────────────────────────────────────────────────
データの性質       5           5      3         4
  (構造化データ)

アクセスパターン   5           4      3         4
  (OLTP, JOIN多)

一貫性要件        5           5      2         3
  (強一貫性必須)

スケール要件      5           5      5         4
  (〜100GB)

運用体制          5           5      5         5
  (AWS RDS/マネージド)

エコシステム      5           4      3         3
  (チーム経験)
──────────────────────────────────────────────────────
合計              30          28     21        23
──────────────────────────────────────────────────────

結論: PostgreSQL (RDS) が最適

判断の根拠:
- 構造化データのJOIN操作で最も表現力が高い
- ACID保証が在庫管理の一貫性要件を満たす
- 100GB規模なら単一ノードで十分
- チームの既存スキルが活かせる
- RDSでの運用負荷は最小限
============================================================
EOF
```

### 演習3: 別のシナリオでの比較

同じフレームワークを、異なるシナリオに適用する。

```bash
cat << 'EOF'
============================================================
シナリオ: IoTセンサーデータの収集・分析基盤
============================================================

要件:
- 数千台のセンサーから毎秒データ受信
- 時系列データが中心、スキーマは固定
- リアルタイムダッシュボードと過去データの分析
- 結果整合性で十分
- 初期1TB、1年後10TB
- 小規模チーム、GCP利用

                  TimescaleDB  InfluxDB  PostgreSQL  ClickHouse
                  (on GCE)     (Cloud)   (Cloud SQL) (on GCE)
──────────────────────────────────────────────────────────────
データの性質       5            5         3           4
  (時系列データ)

アクセスパターン   5            5         2           5
  (追記+集約)

一貫性要件        4            3         5           3
  (結果整合性可)

スケール要件      4            4         2           5
  (〜10TB)

運用体制          3            5         5           2
  (マネージド優先)

エコシステム      4            4         5           3
  (PostgreSQL経験)
──────────────────────────────────────────────────────────────
合計              25           26        22          22
──────────────────────────────────────────────────────────────

結論: InfluxDB Cloud または TimescaleDB

判断の分岐:
- 運用負荷を最小化するなら InfluxDB Cloud
- PostgreSQLのスキルを活かすなら TimescaleDB
  （TimescaleDBはPostgreSQL拡張であり、既存の
    SQLスキルがそのまま使える）
- ClickHouseは性能面で優れるが、運用負荷が高い
============================================================
EOF
```

### 演習4: 「選ばない」判断

最も重要な演習は、「何を選ばないか」を明確にすることだ。

```bash
cat << 'EOF'
============================================================
アンチパターン: よくある誤った選定理由
============================================================

[1] 「みんなが使っているから」
  → DB-Engines Rankingの上位だから選ぶのは理由にならない
  → あなたのプロジェクトの要件を先に定義せよ

[2] 「最新だから」
  → NewSQLやサーバレスDBが話題だから採用するのは危険
  → 成熟度、エコシステム、チームのスキルを考慮せよ

[3] 「スケールするから」
  → 「将来スケールが必要になるかも」は根拠が弱い
  → 現在の要件と1年後の現実的な予測で判断せよ
  → PostgreSQLの単一ノードは想像以上に強い

[4] 「フレームワークのデフォルトだから」
  → RailsのデフォルトがSQLiteだから本番もSQLiteにはしない
  → フレームワークのデフォルトは開発の手軽さのためであり
    本番の要件とは別の話

[5] 「SQLを書きたくないから」
  → NoSQLはSQLを避けるための選択肢ではない
  → データの性質とアクセスパターンから判断せよ
  → 第22回で見たように、SQLはあらゆる場所に回帰した
============================================================
EOF
```

### 後片付け

この演習はテキスト出力のみのため、後片付けは不要だ。

---

## 5. データベースの地層を読む力——あなたは何を選ぶか

### 50年が教えてくれること

全24回を書き終えて、私の中に残った確信が三つある。

**第一に、データベース技術の本質は50年間変わっていない。** 1950年代のファイルベースのデータ管理が直面した根本的な課題——データの永続化、整合性の保証、効率的な検索、並行アクセスの制御——は、2026年の今も変わらずデータベースの存在理由であり続けている。Coddの1970年の論文が定式化した「データの論理的独立性」は、NoSQLでもNewSQLでもサーバレスDBでも、形を変えて追求されている。技術の表層は激しく変動するが、解くべき問題の本質は驚くほど安定している。

**第二に、すべてのデータベース技術はトレードオフの産物である。** ACIDは一貫性を保証するが、スケーラビリティを制限する。NoSQLはスケーラビリティを実現するが、一貫性を犠牲にする。NewSQLは両立を目指すが、レイテンシとコストが増大する。サーバレスDBは運用負荷を軽減するが、コスト予測とカスタマイズ性を犠牲にする。「銀の弾丸」は存在しない。Fred Brooksが1986年の論文「No Silver Bullet」で指摘したソフトウェア工学の本質的困難は、データベース技術にもそのまま当てはまる。

**第三に、「選ぶ力」は歴史を知ることで磨かれる。** なぜリレーショナルモデルが50年生き残ったのかを知る人間は、次のパラダイムシフトが来たときに「なぜそれが必要なのか」を理解できる。なぜNoSQLが生まれたのかを知る人間は、「NoSQLが不要なケース」も見分けられる。なぜSQLが何度も「死んだ」と宣告されながら復活したのかを知る人間は、表層的な技術トレンドに流されない。

### 「Enable」——自走するエンジニアのために

この連載の動機は、冒頭に書いた通り「Enable」だ。依存関係を作るのではなく、自走できる状態を作ること。

「PostgreSQLを使え」とは言わない。「DynamoDBを使うな」とも言わない。私が言いたいのは、こういうことだ。

**データベースを「選んで」使え。**

選ぶためには、データベースが「何を解決しているか」を知れ。何を解決しているかを知るためには、データベースがなかった時代——ファイルベースのデータ管理しかなかった時代（第2回）を知れ。なぜリレーショナルモデルが生まれたのかを知るためには、階層型データベースの制約（第3回）を知れ。なぜNoSQLが生まれたのかを知るためには、RDBのスケーリング限界（第11回）とCAP定理（第12回）を知れ。

50年の地層を読む力が、次の10年のデータ管理を切り拓く。

### 最後の問い

この連載を通じて、私は一貫して読者に問いかけてきた。最後にもう一つだけ問いを投げたい。

あなたが今使っているデータベース——PostgreSQLでもMySQLでもDynamoDBでもMongoDBでもSQLiteでもいい——を選んだ理由は何だろうか。チームの慣習か。フレームワークのデフォルトか。クラウドサービスの推奨か。

もしその選択に「根拠」が言えるなら、あなたはすでに地層を読む力を持っている。

もし「なんとなく」だったなら、この連載が少しでも「根拠」を与えられたなら、書いた甲斐がある。

データベースの地層は、あなたの足元に広がっている。掘り下げる価値は、必ずある。

---

### 参考文献

- Codd, E.F., "A Relational Model of Data for Large Shared Data Banks", Communications of the ACM, Vol.13, No.6, pp.377-387, 1970. <https://dl.acm.org/doi/10.1145/362384.362685>
- Brewer, E., "Towards Robust Distributed Systems", PODC 2000 Keynote, 2000. <https://people.eecs.berkeley.edu/~brewer/cs262b-2004/PODC-keynote.pdf>
- DeCandia, G. et al., "Dynamo: Amazon's Highly Available Key-value Store", SOSP 2007. <https://dl.acm.org/doi/10.1145/1294261.1294281>
- Corbett, J.C. et al., "Spanner: Google's Globally-Distributed Database", OSDI 2012. <https://research.google/pubs/spanner-googles-globally-distributed-database-2/>
- Kleppmann, M., "Designing Data-Intensive Applications", O'Reilly Media, 2017. <https://dataintensive.net/>
- Brooks, F.P., "No Silver Bullet—Essence and Accident in Software Engineering", IEEE Computer, 1986.
- Stack Overflow, "2025 Developer Survey", 2025. <https://survey.stackoverflow.co/2025/technology>
- DB-Engines, "DB-Engines Ranking", 2026. <https://db-engines.com/en/ranking>
- Aslett, M., "What we talk about when we talk about NewSQL", 451 Research, 2011. <https://blogs.the451group.com/information_management/2011/04/06/what-we-talk-about-when-we-talk-about-newsql/>

---

**連載完結。** 全24回にわたり「データベースの地層——RDBからNewSQLまで、データ管理50年の地殻変動」をお読みいただいた皆様に、心から感謝を申し上げる。この連載が、あなたのデータベース選定の「判断基準」を一つでも増やすことができたなら、それが筆者にとって最大の報酬である。
