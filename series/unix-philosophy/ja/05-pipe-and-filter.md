# UNIXという思想

## ——パイプ、プロセス、ファイル――すべてはここから始まった

### 第5回：「パイプとフィルタ——ソフトウェア合成の原点」

**連載「UNIXという思想——パイプ、プロセス、ファイル――すべてはここから始まった」**
**著：佐藤裕介（Engineers Hub株式会社 CEO / Technical Lead）**

---

**この回で学べること：**

- Doug McIlroyが1964年に記した「ガーデンホース」のメモから、1973年のパイプ実装に至る9年間の経緯
- パイプ以前のUNIXにおけるデータ受け渡し——中間ファイル方式の限界
- pipe()システムコールの内部動作——カーネルバッファ、ファイルディスクリプタ、プロセスの並行実行
- 名前付きパイプ（FIFO）によるプロセス間通信の拡張
- パイプの設計思想が関数型プログラミングの|>演算子やETLパイプラインに受け継がれた系譜
- straceによるパイプの内部観察と、独自フィルタプログラムの実装ハンズオン

---

## 1. `|` 一文字が変えたもの

1999年のある夜、私はSlackwareの黒いターミナルの前に座っていた。

Webサーバのアクセスログからエラーを集計する必要があった。ログファイルは数万行。当時の私が知っていた方法は、まずgrepでエラー行を一時ファイルに書き出し、その一時ファイルをsortに食わせ、その結果をまた別の一時ファイルに書き出し、それをuniqで畳む——という手順だった。

```bash
grep error /var/log/apache/access.log > /tmp/errors.txt
sort /tmp/errors.txt > /tmp/sorted.txt
uniq -c /tmp/sorted.txt > /tmp/counted.txt
sort -rn /tmp/counted.txt
rm /tmp/errors.txt /tmp/sorted.txt /tmp/counted.txt
```

5行のコマンドと3つの一時ファイル。ディスクに何度も書いて読んで、最後に消す。動くには動いた。だが、ログファイルが巨大になると一時ファイルがディスクを圧迫した。そして何より、手順が冗長だった。

ある日、先輩エンジニアが横から覗き込んで言った。「パイプ使えよ」。

```bash
grep error /var/log/apache/access.log | sort | uniq -c | sort -rn
```

1行だ。一時ファイルはゼロ。ディスクI/Oもゼロ。そしてこのワンライナーは、私が5行で書いた処理より速かった。

驚いたのは速度だけではない。このワンライナーを見た瞬間、私の中で「問題の捉え方」が変わった。それまでの私は、一つのプログラムに処理を詰め込むか、中間ファイルを介して手動でプログラムを繋ぐか——そのどちらかしか知らなかった。パイプは第三の選択肢を示した。プログラムを「直接」繋ぐ。一つのプログラムの出力を、ファイルを介さずに、次のプログラムの入力にする。

`|` 一文字。この記号の裏には、9年越しのアイデアと、一晩の熱狂的な実装と、ソフトウェア設計における根本的な発想の転換が隠れている。

パイプは単なるコマンド連結ではない。パイプは「合成（composition）」の原型だ。独立した部品を繋ぎ合わせて、どの部品にも存在しない新しい機能を生み出す。この合成という概念は、ソフトウェア設計の歴史を貫く一本の糸だ。

パイプとは何か。なぜこの仕組みがUNIXの設計哲学の核心に位置するのか。そして、パイプの発想は現代のソフトウェア設計にどのように受け継がれているのか。

---

## 2. ガーデンホースから`|`へ——パイプ誕生の9年間

### 1964年のメモ——McIlroyの予言

パイプのアイデアは、UNIXそのものよりも古い。

1964年10月11日、Doug McIlroyはBell Labsの内部メモに一つのアイデアを記した。当時、Bell LabsのコンピューティングはIBM 7090や7094でのバッチ処理が主流だった。UNIXが生まれる5年前のことだ。

> We should have some ways of coupling programs like garden hose--screw in another segment when it becomes necessary to massage data in another way. This is the way of IO also.

「プログラムをガーデンホースのように繋ぎ合わせる方法が必要だ——データを別の方法で加工する必要が出てきたら、別のセグメントをねじ込めばいい。これがI/Oのあるべき姿でもある」

Dennis Ritchieはこのメモを「Prophetic Petroglyphs（予言的な岩刻画）」と呼んだ。実際、それは予言だった。McIlroyが描いたビジョンは、9年後にUNIXのパイプとして実現され、半世紀以上にわたってソフトウェア設計の原型であり続けている。

McIlroyのメモが注目に値するのは、その比喩の的確さだ。ガーデンホースは、セグメントを自由に繋ぎ替えられる。ノズルを変えれば水の出方が変わる。延長ホースを足せば遠くまで届く。スプリンクラーを付ければ散水できる。各セグメントは独立した部品であり、標準化されたコネクタで接続される。データの加工を「ホースのセグメント」に喩えたMcIlroyのビジョンは、そのままUNIXのパイプラインの設計思想になった。

### 1970年〜1972年——提案と拒絶の繰り返し

UNIXは1969年に誕生したが、パイプの実装には至らなかった。McIlroyは1970年から1972年にかけて、繰り返しパイプの導入を提案した。

McIlroy自身の回想によれば、彼は「proposal after proposal（提案に次ぐ提案）」をKen Thompsonに持ちかけた。だがThompsonはすぐには動かなかった。アイデアに反対していたわけではない。シェルの構文としてどう表現するかが定まらなかったのだ。

プロセス間でデータを直接受け渡す仕組み自体は、技術的には実装可能だった。問題は「使いやすさ」だ。プログラマがシェルからパイプを自然に使える構文がなければ、この機能は日の目を見ない。

転機はMcIlroyが「pipe」という名前を提案し、シェルの構文を具体的に示したときに訪れた。McIlroyの回想では「Then one day, I came up with a syntax for the shell that went along with the piping, and Ken said, I'm gonna do it（ある日、パイプに合うシェル構文を思いついた。するとKenは"やる"と言った）」。

### 1973年1月——熱狂の一夜

Ken Thompsonが「やる」と言ったとき、彼は本当にやった。

McIlroyは、Thompsonの作業を「one feverish night（熱狂的な一夜）」と表現している。1973年、ThompsonはVersion 3 Unixにpipe()システムコールを追加し、シェルにパイプの構文を組み込み、`pr`や`ov`など複数のユーティリティをフィルタとして使えるよう改修した。一晩でだ。

翌日、Bell Labsの研究者たちの間で何が起きたか。McIlroyの言葉を借りる。

> The next day saw an unforgettable orgy of one-liners as everybody joined in the excitement of plumbing.

「翌日は忘れがたいワンライナーの饗宴となった。誰もがパイプの興奮に加わった」

「plumbing（配管工事）」という言葉が効いている。プログラムを「配管する」——繋ぎ合わせて、データを流す。McIlroyの「ガーデンホース」の比喩が、まさに現実になった瞬間だ。

### 構文の進化——`>`から`|`へ

Version 3 Unixで導入された最初のパイプ構文は、リダイレクション記号を流用した冗長なものだった。McIlroyはこの構文について「almost a page to describe（記述するのにほぼ1ページを要した）」と振り返っている。

数ヶ月後、Thompson自身がより簡潔な表記を提案した。中置の`|`記号だ。この変更はVersion 4 Unix（1973年11月）で採用された。McIlroyによれば、パイプラインの記述は「just four sentences（わずか4文）」で済むようになった。

`|`を入力できないテレタイプ端末——当時は大文字しか出力できない端末も珍しくなかった——のために、`^`（キャレット）が代替記号として使えた。この互換性はBourne shell（1977年）まで維持された。

9年の構想期間を経て、1964年の「ガーデンホース」のアイデアは、1973年の`|`一文字に結晶した。

---

## 3. パイプの内部——カーネルバッファとファイルディスクリプタ

### パイプ以前——中間ファイルの世界

パイプが何を解決したかを理解するには、パイプがなかった時代を想像する必要がある。

パイプ以前のUNIXで、プログラムAの出力をプログラムBの入力にするには、中間ファイルを使うしかなかった。

```
パイプ以前:
  Program A  ──write──→  /tmp/intermediate  ──read──→  Program B

  1. Program A が実行完了し、出力を /tmp/intermediate に書く
  2. Program A が終了する
  3. Program B が /tmp/intermediate を読み、処理を開始する
  4. Program B が終了する
  5. /tmp/intermediate を削除する

パイプ導入後:
  Program A  ──pipe──→  Program B

  1. Program A と Program B が同時に起動する
  2. Program A の出力がカーネルバッファを介して Program B の入力に渡る
  3. 中間ファイルは存在しない
```

中間ファイル方式には三つの問題があった。

第一に、ディスクI/Oのコスト。Program Aの出力は一度ディスクに書かれ、Program Bがそれをディスクから読む。データ量が大きければ、ディスクの読み書きがボトルネックになる。

第二に、ディスク容量の消費。中間ファイルはデータ全体をディスク上に保持する。巨大なログファイルを処理する場合、中間ファイルだけでディスクが溢れることがあった。

第三に、逐次実行の制約。Program Aが完全に終了してからでないと、Program Bは処理を開始できない。データがストリームとして流れてきても、全データがファイルに書き終わるまで待たなければならなかった。

パイプはこの三つの問題をすべて解決した。

### pipe()システムコール——二つのファイルディスクリプタ

パイプの核心は、`pipe()`システムコールだ。

```c
#include <unistd.h>

int pipe(int fd[2]);
```

`pipe()`は二つのファイルディスクリプタを返す。`fd[0]`が読み出し側、`fd[1]`が書き込み側だ。プロセスが`fd[1]`に`write()`したデータは、カーネル内のバッファに格納され、別のプロセスが`fd[0]`から`read()`で取り出す。

シェルがパイプラインを実行するとき、内部では次のことが起きている。

```
シェルの内部動作: cmd1 | cmd2

1. pipe() を呼び、fd[0]（読み出し）と fd[1]（書き込み）を取得
2. fork() で子プロセス1を生成 → cmd1 を実行
   - fd[1] を stdout（fd 1）に dup2()
   - 不要な fd[0], fd[1] を close()
3. fork() で子プロセス2を生成 → cmd2 を実行
   - fd[0] を stdin（fd 0）に dup2()
   - 不要な fd[0], fd[1] を close()
4. 親プロセス（シェル）は fd[0], fd[1] を close() し、両子プロセスの終了を wait()
```

ここで重要なのは`dup2()`だ。`dup2(fd[1], 1)`は、パイプの書き込み側をファイルディスクリプタ1番（標準出力）に複製する。これにより、cmd1が`printf()`や`write(1, ...)`で標準出力に書いたデータは、自動的にパイプに流れる。cmd1自身は、自分の出力がパイプに接続されていることを知らない。ファイルに出力しているのか、端末に出力しているのか、パイプに出力しているのか——cmd1にとっては区別がない。

この「無自覚さ」が、UNIXのパイプの設計上の核心だ。プログラムは標準出力に書くだけでよい。出力先がどこに接続されているかは、プログラムの知るところではない。シェルが接続を決める。プログラムは「配管」から独立している。

### カーネルバッファ——見えない仲介者

パイプの読み書きは、カーネルメモリ内のバッファを介して行われる。

初期のUNIX（Version 6、1975年頃）では、パイプバッファのサイズはわずか4,096バイト——カーネルのブロックサイズと同じだった。それ以前のVersion 3ではさらに小さく、504バイトだった。

現代のLinux（2.6.11以降）では、パイプバッファのデフォルトサイズは65,536バイト（16ページ）だ。Linux 2.6.35以降は、`fcntl()`の`F_GETPIPE_SZ`/`F_SETPIPE_SZ`でバッファサイズを動的に変更できる。

```
パイプバッファの進化:

  初期Unix (V3, 1973)     504 バイト
  Unix V7 (1979)         4,096 バイト
  Linux 〜2.6.10         4,096 バイト（1ページ）
  Linux 2.6.11〜        65,536 バイト（16ページ）
```

バッファが小さいことには意味がある。書き込み側のプロセスがバッファを満たすと、バッファに空きができるまで`write()`がブロック（一時停止）する。読み出し側のプロセスがバッファを空にすると、データが到着するまで`read()`がブロックする。

このブロッキング動作が、パイプラインの自動的なフロー制御を実現する。書き込み側が速すぎれば自動的に減速し、読み出し側が速すぎれば自動的に待機する。プログラマが明示的に同期処理を書く必要はない。カーネルのバッファが、見えない仲介者として両者のペースを調整する。

### パイプラインの並行実行

パイプの最も過小評価されている特性は、並行実行だ。

`cmd1 | cmd2 | cmd3`というパイプラインでは、cmd1、cmd2、cmd3は3つの独立したプロセスとして同時に起動される。cmd1が出力を生成し始めた瞬間から、cmd2はその出力を読み始める。cmd1が全データを出力し終わるのを待つ必要はない。

```
時間軸での動作:

中間ファイル方式:
  cmd1: [==========]
  cmd2:              [==========]
  cmd3:                           [==========]
  ──────────────────────────────────────────→ 時間

パイプライン方式:
  cmd1: [==========]
  cmd2:   [==========]
  cmd3:     [==========]
  ──────────────────────────────────────────→ 時間
```

中間ファイル方式では処理が逐次的に行われる。パイプライン方式では処理がオーバーラップする。データがストリームとして流れ、各プロセスが自分の担当部分を並行して処理する。

これは、現代の用語で言えば「パイプライン並列性（pipeline parallelism）」だ。製造業の組み立てラインと同じ原理である。各工程（プロセス）は自分の作業に専念し、半製品（データ）がベルトコンベア（パイプ）の上を流れていく。

マルチコアCPUが普及した現代では、パイプラインの各プロセスが異なるCPUコアで真に並列に実行される可能性がある。1973年のKen Thompsonは、マルチコアを想定してパイプを設計したわけではない。だが、プロセスの独立性というUNIXの設計原則が、50年後のマルチコア時代に自然と適合した。設計原則が時代を超えるとは、こういうことだ。

### SIGPIPE——壊れたパイプ

パイプラインには、もう一つ重要な仕組みがある。SIGPIPEシグナルだ。

`cmd1 | head -1`を実行したとき、headは最初の1行を読んだ後に終了する。headが終了すると、パイプの読み出し側が閉じられる。このとき、cmd1がまだデータを書き込もうとすると、カーネルはcmd1にSIGPIPEシグナルを送る。cmd1はデフォルトでこのシグナルにより終了する。

この仕組みがなければ、cmd1は読み手のいないパイプに延々とデータを書き続けることになる。SIGPIPEは、パイプラインの「早期終了」を可能にする。読み手が「もう十分だ」と判断した時点で、書き手も停止する。

SIGPIPEの設計は、UNIXの「無駄な仕事はしない」という哲学の表れだ。必要なデータが得られた時点で処理を止める。`grep pattern file | head -1`で最初のマッチ行だけが必要なら、grepはファイル全体を走査する必要はない。headが閉じた時点で、grepもSIGPIPEにより停止する。

---

## 4. フィルタパターン——合成可能性の設計規約

### パイプがもたらした設計の転換

パイプの実装は、UNIXのプログラム設計に根本的な転換をもたらした。

McIlroyは『A Research UNIX Reader』の中で、パイプの登場が「standard-in-standard-out design（標準入力/標準出力設計）を"philosophy（哲学）"の地位に引き上げた」と述べている。パイプ以前にも、標準入力から読んで標準出力に書くプログラムは存在した。だが、パイプの導入後、この設計パターンは意識的に追求される「規約」になった。

Thompsonはパイプの実装と同時に、既存のユーティリティ——`pr`（ページフォーマッタ）や`ov`（オーバーストライク処理）——をフィルタとして使えるよう改修した。そして、パイプ以降に設計されたプログラム——`tr`（文字変換、1973年）、`sed`（ストリームエディタ、1974年）、`m4`（マクロプロセッサ）——は、最初からフィルタパターンを意識して設計された。

### フィルタの設計規約

フィルタとは、「標準入力からデータを読み、何らかの変換を施し、標準出力に結果を書き出すプログラム」だ。この定義は単純だが、合成可能性を実現するための暗黙の規約が含まれている。

```
フィルタの設計規約:

1. データは標準入力から読む
   - ファイル名が引数で指定されていなければ、stdin から読む
   - 引数でファイルを指定できる場合も、stdin からの入力を受け付ける

2. 結果は標準出力に書く
   - 人間向けの修飾（色付け、ヘッダ装飾）は避ける
   - あるいはstdoutがパイプの場合は修飾を自動抑制する

3. エラーメッセージは標準エラー出力に書く
   - stderr にエラーを書くことで、stdout のデータストリームを汚さない
   - パイプラインの中間段階でエラーが発生しても、
     データの流れは維持される

4. 終了コードで成功/失敗を報告する
   - 0 は成功、非0 は失敗
   - パイプラインの制御（&& や ||）に使われる

5. 余計な出力を混ぜない
   - 起動メッセージ、進捗表示、バナーを stdout に書かない
   - McIlroy の原則: "Don't clutter output with extraneous information"
```

この5つの規約は、どこかに公式文書として定義されているわけではない。UNIXのコマンド群の設計実践から抽出された暗黙の合意だ。だが、この規約に従わないプログラムは、パイプラインの中で「壊れた部品」になる。標準出力に進捗バーを書くプログラム、エラーメッセージをstdoutに混ぜるプログラム、入力がパイプからであることを拒否するプログラム——こうしたプログラムは、他のプログラムと合成できない。

フィルタの規約は、プログラムの「インタフェース契約」だ。APIのエンドポイントがリクエスト/レスポンスの形式を定義するように、フィルタは入出力の流儀を定義する。この契約に従うプログラムは、作者が互いの存在を知らなくても、パイプで合成できる。

### 合成可能性（composability）の本質

合成可能性とは、独立した部品を組み合わせて、どの部品にも存在しない新しい機能を生み出す能力だ。

パイプラインにおいて、合成可能性を支えているのは以下の条件だ。

**統一的なインタフェース。** すべてのフィルタが、同じ形式——バイトストリーム——で入出力を行う。grepの出力形式とsortの入力形式は、何の変換もなしに接続できる。両者がテキスト行を扱うという暗黙の合意があるからだ。

**副作用の最小化。** フィルタは入力を読み、出力を書く。それ以外のことは——ファイルの作成、環境変数の変更、グローバルな状態の操作——原則として行わない。副作用がないから、どの順番で組み合わせても安全だ。

**独立性。** パイプラインの各段階のプログラムは、前後のプログラムの存在を知らない。grepは自分の出力がsortに渡されることを知らないし、sortは自分の入力がgrepから来ていることを知らない。この無関心さが、任意の組み合わせを可能にする。

この三つの条件を、関数型プログラミングの用語で言い換えることもできる。統一的なインタフェースは「型の一致」であり、副作用の最小化は「純粋関数」であり、独立性は「参照透過性」だ。UNIXのパイプラインと関数型プログラミングの関数合成は、異なる文脈で同じ原理を表現している。

### パイプと関数合成——`|`から`|>`へ

UNIXのパイプ演算子`|`と、関数型プログラミングのパイプフォワード演算子`|>`の類似は偶然ではない。

F#は2003年にパイプフォワード演算子`|>`を標準ライブラリに導入した。UNIXシェルの`|`にインスパイアされたこの演算子は、関数合成を左から右に読める形で記述する。

```
UNIXパイプライン:
  cat data.txt | grep error | sort | uniq -c

F# のパイプフォワード:
  data |> List.filter isError |> List.sort |> List.countBy id

Elixir のパイプ:
  data |> Enum.filter(&error?/1) |> Enum.sort() |> Enum.frequencies()
```

`|>`演算子はF#からElixir、OCaml、Juliaへと広がった。Rの`%>%`演算子（magrittrパッケージ）、Clojureの`->`マクロ、さらにはJavaScriptのTC39パイプライン提案やC++20のrangesライブラリの`|`も、同じ系譜にある。

メカニズムは全く異なる。UNIXのパイプはプロセス間通信であり、カーネルバッファとファイルディスクリプタを使う。`|>`演算子は関数合成の糖衣構文であり、コンパイラが関数呼び出しに変換する。だが、「データを変換のチェーンに流す」という発想は同一だ。

数学的に見れば、UNIXパイプラインは関数合成（function composition）のインスタンスだ。`f | g | h`は`h(g(f(x)))`に対応する。ただし、数学の関数合成は右から左に読む（`h ∘ g ∘ f`）のに対し、パイプは左から右に読む。データの流れる方向に記述が一致する——この直感的な読みやすさが、パイプ記法の強みだ。

### ETLパターンとの接続

UNIXパイプラインは、データエンジニアリングの世界で「コマンドラインのETL」と呼ばれることがある。

ETL（Extract, Transform, Load）は、データを抽出し、変換し、格納する3段階の処理パターンだ。

```
ETLパターン:
  Extract    ──→  Transform  ──→  Load
  (データ抽出)     (データ変換)     (データ格納)

UNIXパイプライン:
  cat data   ──→  awk/sed/grep ──→  tee output
  (読み出し)       (変換/抽出)       (書き出し)
```

構造は同じだ。入力を取り、変換を施し、出力する。UNIXパイプラインとETLの違いは、スケールと実行モデルにある。UNIXパイプラインは単一マシン上でストリーム処理を行う。伝統的なETLはバッチ処理として大量データを定期的に移動する。だが、Apache KafkaやApache FlinkのようなモダンなストリーミングETLは、UNIXパイプに近いリアルタイムの逐次処理モデルを採用している。

1973年のパイプの発想が、2020年代のストリーミングデータ基盤に生きている。パイプが実現した「データをストリームとして流し、各段階が独立して変換を行う」というアーキテクチャは、50年を経ても有効なのだ。

---

## 5. ハンズオン：パイプの内部を観察し、自作フィルタを組み込む

ここからは手を動かす。パイプの内部動作をstraceで観察し、Cで自作のフィルタプログラムを書き、名前付きパイプによるプロセス間通信を体験する。

### 環境構築

```bash
docker run -it --rm ubuntu:24.04 bash
```

コンテナ内で必要なツールを用意する。

```bash
apt-get update && apt-get install -y strace gcc
```

### 演習1：straceでパイプの内部を観察する

まず、単純なパイプの内部動作をstraceで見てみる。

```bash
strace -f -e trace=pipe,pipe2,dup2,clone,write,read,close \
  bash -c 'echo hello | cat' 2>&1 | head -40
```

`-f`は子プロセスもトレースするオプションだ。`-e trace=...`で観察するシステムコールを絞っている。

出力の中から、パイプに関するシステムコールを探す。

```bash
# より読みやすい形で、パイプの生成と接続だけを抽出
strace -f -e trace=pipe,pipe2,dup2 bash -c 'echo hello | cat' 2>&1
```

出力には次のような行が含まれるはずだ（PID番号は実行ごとに異なる）。

```
pipe([3, 4])                = 0      # パイプ生成: fd[0]=3(読), fd[1]=4(書)
[pid XXXX] dup2(4, 1)       = 1      # 子プロセス1: fd[1]をstdoutに複製
[pid YYYY] dup2(3, 0)       = 0      # 子プロセス2: fd[0]をstdinに複製
```

`pipe([3, 4])`でカーネルがパイプを作成し、ファイルディスクリプタ3（読み出し）と4（書き込み）を返している。`dup2(4, 1)`で書き込み側をstdout（fd 1）に、`dup2(3, 0)`で読み出し側をstdin（fd 0）に接続している。

これが`echo hello | cat`の舞台裏だ。echoは自分の標準出力がパイプに接続されていることを知らないし、catは自分の標準入力がパイプから来ていることを知らない。シェルがパイプを作り、ファイルディスクリプタを差し替え、両プロセスを「接続」している。

### 演習2：パイプバッファのブロッキングを体験する

パイプバッファが満杯になるとwriteがブロックすることを確認する。

```bash
# パイプバッファのサイズを確認
cat /proc/sys/fs/pipe-max-size

# 大量のデータを書き込み、読み出しを遅延させる
# yesは"y"を無限に出力し続ける
# sleepは5秒間読み出しを行わない → 書き込みがブロックされる
timeout 3 bash -c '
  yes | (sleep 2; wc -c) 2>/dev/null
' 2>/dev/null
```

`yes`はバッファが満杯になるとブロックされ、`sleep 2`の後に`wc -c`が読み出しを開始すると再びデータが流れ始める。

### 演習3：Cで自作フィルタを書く

標準入力から行を読み、各行に行番号と文字数を付加するフィルタを書く。

```bash
cat << 'EOF' > /tmp/lineinfo.c
/* lineinfo: 各行に行番号と文字数を付加するフィルタ */
#include <stdio.h>
#include <string.h>

int main(void) {
    char buf[4096];
    int lineno = 0;

    while (fgets(buf, sizeof(buf), stdin) != NULL) {
        lineno++;
        /* 改行を除いた文字数を計算 */
        size_t len = strlen(buf);
        if (len > 0 && buf[len - 1] == '\n') {
            len--;
        }
        printf("%4d [%3zu chars] %s", lineno, len, buf);
    }

    return 0;
}
EOF
gcc -o /tmp/lineinfo /tmp/lineinfo.c
```

このフィルタをパイプラインに組み込む。

```bash
# /etc/passwdの最初の5行に行番号と文字数を付加
head -5 /etc/passwd | /tmp/lineinfo
```

出力例:

```
1 [ 29 chars] root:x:0:0:root:/root:/bin/bash
2 [ 32 chars] daemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologin
...
```

自作のフィルタは、既存のUNIXコマンドと自由に組み合わせられる。

```bash
# grepで特定のユーザを抽出 → 自作フィルタで情報付加 → sortで並べ替え
grep -E '^(root|nobody|www-data)' /etc/passwd | /tmp/lineinfo | sort -t'[' -k2 -n
```

フィルタの規約——stdinから読み、stdoutに書き、行指向で処理する——に従っている限り、自作プログラムもUNIXコマンドの一員として振る舞える。

### 演習4：名前付きパイプ（FIFO）でプロセスを接続する

通常のパイプは、シェルが`|`で繋いだプロセス間でのみ使える。名前付きパイプ（FIFO）は、ファイルシステム上に「名前」を持ち、血縁関係のないプロセス同士を接続する。

```bash
# 名前付きパイプを作成
mkfifo /tmp/myfifo
ls -l /tmp/myfifo   # 先頭が 'p' であることを確認（pipeの'p'）
```

ターミナル1つで、書き込み側と読み出し側を別プロセスとして起動する。

```bash
# 読み出し側をバックグラウンドで起動
cat /tmp/myfifo &
READER_PID=$!

# 書き込み側からデータを送る
echo "Hello from writer" > /tmp/myfifo
echo "Second message" > /tmp/myfifo

# 読み出し側を停止
wait $READER_PID 2>/dev/null

# 別の使い方: 名前付きパイプを使ってプロセス間通信
mkfifo /tmp/logpipe

# ログ処理プロセスをバックグラウンドで起動
(while read line; do
    echo "[$(date +%H:%M:%S)] $line"
done < /tmp/logpipe) &
LOG_PID=$!

# 複数のプロセスからログを送信
echo "Process A started" > /tmp/logpipe
echo "Process B started" > /tmp/logpipe
echo "Process A completed" > /tmp/logpipe

# 停止と後片付け
kill $LOG_PID 2>/dev/null
rm -f /tmp/myfifo /tmp/logpipe
```

名前付きパイプは、通常のパイプが「無名で一時的」なのに対し、ファイルシステム上に永続する。親子関係のないプロセス——異なるシェルセッションから起動されたプロセス——が、ファイルパスを共有するだけで通信できる。

### 演習5：パイプラインの並行動作を視覚化する

パイプラインの各段階が本当に並行して動いていることを確認する。

```bash
cat << 'SCRIPT' > /tmp/parallel_demo.sh
#!/bin/bash
set -euo pipefail

# 各段階でタイムスタンプを出力する遅いフィルタを作る
slow_producer() {
    for i in $(seq 1 5); do
        echo "line $i"
        echo "[Producer] Sent line $i at $(date +%H:%M:%S)" >&2
        sleep 1
    done
}

slow_consumer() {
    while read line; do
        echo "[Consumer] Got '$line' at $(date +%H:%M:%S)" >&2
        echo "$line processed"
        sleep 1
    done
}

echo "=== パイプラインの並行動作 ==="
echo "Producer と Consumer が交互に動作することを確認する"
echo ""
slow_producer | slow_consumer > /dev/null
SCRIPT
chmod +x /tmp/parallel_demo.sh
bash /tmp/parallel_demo.sh
```

出力を見ると、ProducerとConsumerが時間的にオーバーラップして動作していることがわかる。Producerが1行出力し、Consumerがそれを読み、Producerが次の行を出力する——逐次実行ではなく、インターリーブされた並行実行だ。

---

## 6. まとめと次回予告

### この回の要点

- Doug McIlroyは1964年10月11日のBell Labs内部メモで、「プログラムをガーデンホースのように繋ぐ」というアイデアを記した。この構想が実際にUNIXに実装されるまでに9年を要した。名前「pipe」とシェル構文の提案が突破口となり、1973年にKen Thompsonが「熱狂的な一夜」でVersion 3 Unixに実装した

- パイプ以前のUNIXでは、プログラム間のデータ受け渡しに中間ファイルを使っていた。パイプはディスクI/Oを排除し、ディスク容量の消費を解消し、プロセスの並行実行を実現した。中間ファイル方式の三つの問題をすべて解決した

- pipe()システムコールは2つのファイルディスクリプタを返す。シェルはfork()とdup2()を使って、あるプロセスの標準出力を別のプロセスの標準入力に接続する。プログラム自身は、自分の出力がパイプに接続されていることを知らない。この「無自覚さ」がUNIXパイプの設計上の核心だ

- パイプの導入が「標準入力/標準出力設計」を哲学の地位に引き上げた。以降のUNIXプログラムは、フィルタパターン——stdinから読み、変換し、stdoutに書く——を意識的に追求するようになった

- パイプの合成可能性の原理は、F#の|>演算子（2003年）を経由してElixir、OCaml、Juliaに広がり、ETLパイプラインやストリーミングデータ基盤にも受け継がれている。1973年の設計思想が、形を変えながら半世紀以上にわたって生き続けている

### 冒頭の問いへの暫定回答

「パイプは単なるコマンド連結ではない。ソフトウェアの"合成"とは何か？」

暫定的な答えはこうだ。合成とは、独立した部品を繋ぎ合わせて、どの部品にも存在しない新しい機能を生み出すことだ。`grep`はパターンを探すだけだ。`sort`は並べるだけだ。`uniq -c`は畳んで数えるだけだ。だが`grep | sort | uniq -c`は「パターンにマッチする行の出現頻度を集計する」という、どのコマンドにも存在しない機能を生み出す。

合成が成立するためには条件がある。統一的なインタフェース（バイトストリーム）、副作用の最小化（stdinから読みstdoutに書く以外のことをしない）、独立性（前後のプログラムの存在を知らない）。この三つの条件を満たすとき、部品は自由に組み合わせ可能になる。

そして合成の真の価値は、「まだ存在しないプログラムとの組み合わせ」にある。McIlroyが1978年に書いた「as yet unknown program（まだ存在しないプログラム）」——この概念が、パイプの設計を50年以上にわたって有効にし続けている理由だ。あなたが今日書いたフィルタは、あなたがまだ知らないプログラムと組み合わせられる。フィルタの規約に従っている限り。

あなたが設計するシステムのコンポーネントは、「まだ存在しない」相手と合成可能だろうか。その問いに答えられるかどうかで、設計の寿命が変わる。

### 次回予告

次回は「"Everything is a file"——抽象化の極致」。パイプもファイルディスクリプタで操作される。デバイスもファイルディスクリプタで操作される。ソケットもファイルディスクリプタで操作される。UNIXは、あらゆるI/O対象を「ファイル」という一つの抽象に統一した。

`/dev/null`に出力を捨て、`/dev/random`から乱数を読み、`/proc`からプロセス情報を取得する。これらがすべて同じ`open()`, `read()`, `write()`, `close()`で操作できる。この抽象化がなぜ強力なのか。Plan 9はこの原則をどこまで徹底したのか。そして、「すべてはファイルである」という設計は、REST APIの統一インタフェースやクラウドのストレージ抽象化にまで、どのように影響を及ぼしているのか。

`ls -l /dev/null`を打ってみてほしい。先頭の`c`は「キャラクタデバイス」を意味する。通常のファイルでもディレクトリでもないものが、「ファイル」として存在している。この設計判断の意味を、次回は掘り下げる。

---

## 参考文献

- M.D. McIlroy, "Prophetic Petroglyphs" (1964年10月11日のBell Labs内部メモ), Dennis Ritchieのページに保存: <https://www.nokia.com/bell-labs/about/dennis-m-ritchie/mdmpipe.html>
- M.D. McIlroy, "A Research UNIX Reader: Annotated Excerpts from the Programmer's Manual, 1971-1986": <https://www.cs.dartmouth.edu/~doug/reader.pdf>
- Pipeline (Unix) — Wikipedia: <https://en.wikipedia.org/wiki/Pipeline_(Unix)>
- Thompson shell — Wikipedia: <https://en.wikipedia.org/wiki/Thompson_shell>
- pipe(7) — Linux manual page: <https://man7.org/linux/man-pages/man7/pipe.7.html>
- Named pipe — Wikipedia: <https://en.wikipedia.org/wiki/Named_pipe>
- "Pipe: How the System Call That Ties Unix Together Came About", The New Stack: <https://thenewstack.io/pipe-how-the-system-call-that-ties-unix-together-came-about/>
- "How are Unix pipes implemented?", toroid.org: <https://toroid.org/unix-pipe-implementation>
- "An In-Depth Look at Pipe and Splice implementation in Linux kernel", Oracle: <https://blogs.oracle.com/linux/post/pipe-and-splice>
- Bozhidar Batsov, "The origin of the pipeline operator (|>)", 2025: <https://batsov.com/articles/2025/05/22/the-origin-of-the-pipeline-operator/>
- M.D. McIlroy, E.N. Pinson, B.A. Tague, "UNIX Time-Sharing System: Foreword", The Bell System Technical Journal, Vol. 57, No. 6, Part 2, July-August 1978
- Brian W. Kernighan, Rob Pike, "The UNIX Programming Environment", Prentice Hall, 1984
