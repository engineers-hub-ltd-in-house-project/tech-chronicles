# クラウドの考古学

## ——メインフレームからサーバーレスへ、計算資源の民主化史

### 第1回：クラウドなしでサーバを立てられるか

**連載「クラウドの考古学——メインフレームからサーバーレスへ、計算資源の民主化史」**
**著：佐藤裕介（Engineers Hub株式会社 CEO / Technical Lead）**

---

**この回で学べること：**

- クラウドが「空気」になった世界で、私たちが見失っているもの
- 計算資源の本質的な構成要素——CPU、メモリ、ストレージ、ネットワーク
- クラウドが隠蔽している抽象化のレイヤーの全体像
- QEMUで仮想マシンを手動構築し、クラウドの裏側を体感する方法

---

## 1. 「EC2を使わずにWebサーバを公開して」

数年前、私はあるプロジェクトの採用面談で、実務経験4年ほどの若いインフラエンジニアと話をしていた。彼の経歴書にはAWS、Terraform、Kubernetesの実績が並んでいた。CloudFormationでVPCを設計し、EKSクラスタを運用し、GitHub Actionsでデプロイパイプラインを構築している。2020年代のインフラエンジニアとして、申し分のないスキルセットだった。

面談の終盤、私は少し意地悪な質問をした。「もしAWSもGCPもAzureも使えなかったら、どうやってWebサーバを公開する？」

彼は一瞬固まった。それから、少し考えて「VPSを契約して……」と答えた。

「VPSも使えないとしたら？」

沈黙が長くなった。「……さくらの専用サーバとかですか？」

間違ってはいない。だが、彼の目には、答えの先が見えていない不安があった。「そこから先はどうする？　サーバに電源が入って、OSが起動して、ネットワークに接続されるまでの過程を、全部自分でやるとしたら？」

彼は正直に答えた。「やったことがないので、わかりません」

私はその正直さを買った。知らないことを知らないと言えるのは美徳だ。だが同時に、ある種の断絶を感じた。彼は `terraform apply` でVPCとEC2を立ち上げることができる。だが、その `terraform apply` の先で何が起きているか——物理サーバのどこに電源ケーブルが刺さり、どうやってネットワークパケットがインターネットに到達するのか——その実感を持っていない。

これは彼個人の問題ではない。構造的な問題だ。

2020年代にキャリアを始めたエンジニアにとって、クラウドは「空気」である。呼吸するように `aws ec2 run-instances` と打ち、数分後にはSSHで接続できるサーバが手に入る。Terraformで宣言すれば、VPC、サブネット、セキュリティグループ、ロードバランサー、オートスケーリンググループが一式揃う。この体験は素晴らしい。20年前の私からすれば、魔法のようだ。

だが、空気の成分を知らない人間は、空気が薄くなったとき何が起きているか理解できない。高山で息苦しくなったとき、「酸素分圧が下がっている」と理解できるのか、それとも単に「苦しい」と感じるだけなのか。この差は、平地にいるかぎり見えない。

クラウドが「空気」になった世界で、私たちは何を見失ったのか。

この連載は、その問いから始まる。メインフレームの時分割から始まった「他人の計算機を借りる」という発想が、70年をかけてどのように進化し、今日のクラウドコンピューティングに至ったのか。その系譜を24回にわたって辿り直す。

あなたはクラウドを「選んで」使っているだろうか。それとも、他に選択肢を知らないから使っているだろうか。

---

## 2. 数字が語る「クラウドの支配」

まず、現状を数字で確認しよう。クラウドコンピューティングがどれほど深く、広く、現代のIT基盤に浸透しているかを知ることが出発点になる。

### 市場規模——7,000億ドルの巨大産業

Gartnerの調査によれば、2024年の世界IaaS（Infrastructure as a Service）市場は前年比22.5%成長し、1,718億ドルに達した。IaaSだけでこの規模である。PaaS、SaaS、BPaaSを含むパブリッククラウド全体の支出は、2024年に5,957億ドル、2025年には7,234億ドルに達すると予測されている。

7,234億ドル。日本円に換算すれば100兆円を超える。この金額は、世界のIT支出全体の中でも突出した伸び率を示している。企業がクラウドに投じる金額は、もはや「IT予算の一部」ではなく「IT予算の主要構成要素」になった。

### 三強体制——AWSが切り拓き、Azure/GCPが追う

IaaS市場における勢力図は明確だ。Gartnerの2024年データでは、AWSがIaaS売上648億ドル・シェア37.7%でトップ。Microsoftが23.9%で2位。上位5社で市場の82.1%を占める。

Synergy Research Groupの2025年Q2データでは、クラウドインフラ全体でAWS 30%、Azure 20%、GCP 13%。上位3社で63%。四半期の支出は990億ドルに達し、前年同期比25%増で成長し続けている。

Stack Overflow Developer Survey 2024によれば、プロフェッショナル開発者のクラウドプラットフォーム利用率はAWS 52.2%、Azure 29.7%、GCP 24.9%だった。65,000人以上の回答者を持つこの調査は、開発者の実態を映す鏡として信頼性が高い。

これらの数字が示すのは、クラウドが一部の先進的企業の選択肢ではなく、開発者の過半数が日常的に利用するインフラ基盤になったという事実だ。

### 「前提」としてのクラウド

クラウドの浸透は、単なる「利用率の上昇」では語りきれない。Terraformの定義ファイル、AWS CDKのコード、Kubernetesのマニフェスト——現代のインフラ管理は、そのほとんどがクラウドプロバイダのAPIを前提として設計されている。CI/CDパイプラインはクラウド上で動作し、監視ツールはCloudWatchやDatadogのクラウドサービスに依存し、ログはS3やCloudWatch Logsに集約される。

かつて、OSがソフトウェアの前提条件だったように、クラウドが開発プロセスの前提条件になった。

私自身、この10年でその変化を体感してきた。2010年代前半、私はまだオンプレミスとクラウドの「併用」を意識的に選択していた。どのワークロードをAWSに載せ、どれをオンプレミスに残すか——その判断にはコスト計算と技術的検討が伴った。だが2020年代に入ると、新規プロジェクトで「オンプレミスにする」という選択肢が検討されること自体が減った。クラウドが「選択」から「前提」に変わった瞬間を、私は確かに目撃した。

だが、「前提」として無批判に受け入れることと、「理解した上で選択」することの間には、決定的な差がある。

---

## 3. 計算資源の考古学——「他人の計算機を借りる」70年の系譜

ここで少し長い旅に出よう。クラウドの「起源」を探る旅だ。

クラウドコンピューティングの本質は何か。突き詰めれば、「他人の計算機を借りる」という行為に帰着する。そしてこの行為の歴史は、2006年のAWS EC2よりもはるかに古い。

### 1961年——「コンピューティングはユーティリティになる」

1961年、人工知能研究の先駆者であるJohn McCarthyが、MITの100周年記念講演でこう述べた。「コンピューティングは、いつか電話システムのような公共ユーティリティとして組織化されるかもしれない」。各利用者は実際に使用した容量だけを支払い、非常に大きなシステムの特性であるすべてのプログラミング言語にアクセスできる——と。

この発言は1961年のものだ。AWSの登場より45年も前である。McCarthyが描いたビジョンは、驚くほど正確に現代のクラウドを予言していた。従量課金。大規模な計算資源への共有アクセス。プラットフォーム上の多様なサービス。

ただし、McCarthyの構想は当時の技術的制約のもとでは実現しなかった。1960年代後半にユーティリティコンピューティングの概念は注目を集めたが、1970年代半ばにはハードウェア、ソフトウェア、通信技術のいずれもが未成熟であるとして下火になった。概念が技術に先行しすぎていたのだ。

### 1964年——メインフレームと「計算資源の共有」

McCarthyの講演から3年後の1964年4月7日、IBMがSystem/360を発表した。コンピュータ史に残る画期的な製品ファミリーである。System/360は、異なるモデル間でソフトウェアの互換性を保証した最初のメインフレームだった。

System/360は、仮想メモリ対応の360/67モデルでタイムシェアリングシステム（TSS/360）の実現を試みた。TSS/360は遅延と不安定さに苦しみ、正式な製品としては成功しなかったが、この試みの中からCP-67——後のVM/370へと発展する仮想マシンモニタの原型——が生まれた。

タイムシェアリングの概念は、MITのCTSS（Compatible Time-Sharing System、1961年、Fernando Corbato）やMultics（1964年〜、MIT/GE/Bell Labs）で既に実践されていた。一台のメインフレームに複数のユーザーがターミナルからアクセスし、あたかも自分専用の計算機であるかのように利用する。CPUの処理時間をスライスして各ユーザーに分配し、メモリを保護して他のユーザーのデータにアクセスできないようにする。

この仕組みの本質は何だろうか。計算資源を共有し、必要なだけ切り出して提供する。各ユーザーには仮想的に独立した環境を見せる。物理的な計算機を意識させない。

これは、AWSのEC2がやっていることと原理的に同じだ。

もちろん、ターミナルがAPIに、メインフレームがハイパーバイザに、タイムスライスが仮想マシンに置き換わっている。「だけ」と言うには語弊があるが、根底にある設計思想——計算資源を共有し、必要なだけ切り出して提供する——は、60年以上変わっていない。

### 1999年〜2007年——仮想化という架け橋

McCarthyの構想とクラウドの実現を橋渡ししたのが、仮想化技術だった。

1999年、VMware WorkstationがリリースされX86アーキテクチャ上での実用的な仮想化が幕を開けた。2001年にはVMware ESX Serverが登場し、エンタープライズ向けの仮想化基盤が整った。一台の物理サーバ上で複数のOSを同時に動作させる——この技術が、クラウドの物理的基盤となる。

2003年にはXen（ケンブリッジ大学のIan Pratt、Keir Fraserらが開発）がリリースされ、オープンソースの仮想化が始まった。Xenの準仮想化アプローチは、AWSのEC2初期版の基盤技術として採用されることになる。

同じ2003年、Fabrice BellardがQEMU（Quick EMUlator）の開発を開始した。2007年にはKVM（Kernel-based Virtual Machine）がLinuxカーネル2.6.20に統合され、Linuxカーネル自体がハイパーバイザとなった。同年、InnoTek GmbHがVirtualBoxをオープンソースとして公開した（VirtualBoxは2008年にSun Microsystemsが買収、2010年にはOracleが引き継いだ）。

仮想化技術の成熟は、「他人の計算機を借りる」というMcCarthyの構想を、ようやく技術的に実現可能にした。一台の物理マシンを複数の仮想マシンに分割し、それぞれを独立した環境として提供する。この「分割」と「隔離」の技術があったからこそ、クラウドは生まれた。

### 2006年——クラウド元年

2006年3月、AWSがS3（Simple Storage Service）のベータ版を公開した。そして2006年8月25日、EC2（Elastic Compute Cloud）のパブリックベータが発表された。

EC2のベータ公開時、利用可能なインスタンスタイプはm1.smallのみ。仮想化基盤はXen。永続ストレージはなく（EBSの登場は2008年）、インスタンスを停止すればデータは消えた。今の基準で見れば、極めて原始的なサービスだった。

だが、このサービスが革命的だった理由は、仮想サーバを提供したことではない。APIでサーバのライフサイクルを制御でき、必要なときだけ使い、時間単位で課金される——この設計思想がすべてを変えた。

私が初めてEC2を触ったのは2008年のことだ。APIを叩くと数分でサーバが立ち上がった。使い終わったら `terminate` する。月額固定ではなく時間課金。「サーバは消耗品になったのだ」——そう感じた瞬間の衝撃は、今でも鮮明に覚えている。

それ以前の私は、サーバを「大事に使うもの」として扱っていた。物理サーバを秋葉原で買い、データセンターに車で運び込み、ラックに固定し、ケーブルを結線し、OSをインストールし、何ヶ月、何年と運用する。壊れたら修理し、スペックが足りなくなったら増設する。サーバは「資産」であり、「責任」だった。

EC2は、その前提を根底からひっくり返した。

---

## 4. 計算資源の構成要素——クラウドは何を隠しているのか

ここからが本題だ。クラウドが「空気」になったとき、空気の成分を理解するためには、計算資源の本質的な構成要素を知る必要がある。

計算資源は、突き詰めれば4つの要素で構成される。**CPU（計算能力）**、**メモリ（一時記憶）**、**ストレージ（永続記憶）**、**ネットワーク（通信）**。クラウドがやっていることは、この4つの物理資源を抽象化し、API越しに切り出して提供することだ。

### CPU——計算する能力の抽象化

物理サーバには物理CPUコアがある。Intel Xeonの24コアか、AMD EPYCの64コアか。クロック周波数がいくつで、キャッシュ容量がどれだけか。

クラウドは、これを「vCPU」という単位に抽象化する。AWS EC2のt3.microは2 vCPU、c7g.xlargeは4 vCPU。利用者はvCPUの数だけを意識すればよく、その裏で物理CPUのどのコアが割り当てられているかを知る必要がない。

だが、この抽象化には代償がある。同じ「2 vCPU」でも、物理ホスト上の他のテナントがCPUを酷使していれば、自分の処理性能は低下する。いわゆる「Noisy Neighbor」問題だ。クラウドは「他人の計算機を借りている」のだから、「他人」の行動に影響を受ける。この事実は、抽象化の向こう側に常に存在する。

### メモリ——一時記憶の抽象化

物理サーバのDIMM（Dual Inline Memory Module）は、DDR5-4800のECC対応メモリだったりする。容量、速度、エラー訂正能力。これらは物理的な実体だ。

クラウドでは「8 GiB」「16 GiB」といった数値だけが提示される。メモリの物理的な種類や速度は意識する必要がない。だが、インスタンスタイプによってメモリ帯域幅は異なるし、NUMAアーキテクチャの影響で性能にムラが出ることもある。

### ストレージ——永続記憶の抽象化

物理サーバのストレージは、SATAのHDDか、NVMeのSSDか、あるいはSANのLUNか。それぞれIOPS（Input/Output Operations Per Second）とスループット、レイテンシの特性が異なる。

クラウドは、これをブロックストレージ（AWS EBS）、オブジェクトストレージ（S3）、ファイルストレージ（EFS）といった抽象に分割する。EBSのgp3ボリュームは3,000ベースIOPS。io2は最大64,000 IOPS。数字を指定すれば、その性能が得られる——ことになっている。だが物理的には、それらのボリュームは分散ストレージシステムの上に構築されており、ネットワークを経由してデータにアクセスしている。ローカルストレージとは本質的に異なる遅延特性を持つ。

### ネットワーク——通信の抽象化

物理サーバのネットワークは、NICの速度（1Gbps? 10Gbps? 25Gbps?）、スイッチのトポロジ、BGPの経路、ファイアウォールのルール。これらが重層的に組み合わさって、パケットが到達する。

クラウドは、VPC（Virtual Private Cloud）、サブネット、セキュリティグループ、ルートテーブルといった論理的な構成要素に抽象化する。物理ネットワークの上にソフトウェア定義のオーバーレイネットワーク（VXLANなど）が構築され、テナントごとに論理的に隔離された仮想ネットワークが提供される。

この抽象化によって、利用者は物理ネットワークのトポロジを意識する必要がなくなった。だが、AZ（Availability Zone）間の通信レイテンシはリージョン内であっても数ミリ秒のオーダーで存在するし、リージョン間ではさらに大きくなる。物理的な「距離」は、どれだけ抽象化しても消せない。

### 抽象化のレイヤーケーキ

```
┌─────────────────────────────────────────────────┐
│             アプリケーション                     │ ← 開発者が書くコード
├─────────────────────────────────────────────────┤
│         コンテナ / サーバーレス                  │ ← Docker, Lambda
├─────────────────────────────────────────────────┤
│              仮想マシン                          │ ← EC2 インスタンス
├─────────────────────────────────────────────────┤
│            ハイパーバイザ                        │ ← Nitro, KVM, Xen
├─────────────────────────────────────────────────┤
│              物理サーバ                          │ ← CPU, メモリ, SSD
├─────────────────────────────────────────────────┤
│    電力 / 冷却 / ネットワーク / 物理施設        │ ← データセンター
└─────────────────────────────────────────────────┘
```

クラウドの利用者が日常的に意識するのは、このスタックの上位2〜3層だけだ。`aws ec2 run-instances` と入力したとき、APIリクエストがリージョンのエンドポイントに到達し、認証・認可が行われ、利用可能な物理ホストが選択され、ハイパーバイザがVMを起動し、仮想ネットワークインターフェースが作成され、EBSボリュームがアタッチされ、OSがブートする。この一連のプロセスを、APIの一行が隠蔽している。

隠蔽していること自体は悪ではない。むしろ、これこそがクラウドの価値だ。だが、隠蔽されていることを「知らない」のと「知った上で任せている」のでは、決定的に異なる。なぜなら、障害が起きたとき——そして障害は必ず起きる——隠蔽の向こう側を想像できない人間は、打つ手がなくなるからだ。

2011年、NISTは Special Publication 800-145において、クラウドコンピューティングを「共有された構成可能な計算資源のプールへのオンデマンドなネットワークアクセスを可能にするモデル」と定義した。そしてクラウドの5つの基本特性を挙げた。オンデマンド・セルフサービス。広範なネットワークアクセス。リソースプーリング。迅速な弾力性。計量可能なサービス。

これらの特性は、メインフレーム時代のタイムシェアリングから連綿と受け継がれてきた設計思想の洗練された表現である。「リソースプーリング」は1960年代のメインフレーム共有の発展形だし、「計量可能なサービス」はMcCarthyが1961年に描いた「使った分だけ支払う」の実現だ。

---

## 5. ハンズオン——仮想マシンを「手で」構築する

ここまで読んだあなたに、一つ提案がある。クラウドが隠蔽しているものを体感するために、自分の手で仮想マシンを構築してみないか。

AWS EC2のインスタンスを起動するとき、裏側ではハイパーバイザが仮想マシンを作成し、CPUコアを割り当て、メモリを確保し、仮想ディスクを接続し、仮想ネットワークインターフェースを設定している。このプロセスを、QEMUを使って自分の手でやってみる。

### 環境

- Docker（Ubuntu 24.04ベースコンテナ）
- QEMU（マシンエミュレータ・仮想化ソフトウェア）
- Alpine Linux（軽量ディストリビューション、ISOイメージ）

### 演習1：QEMUで仮想マシンを起動する

まず、QEMUをインストールし、仮想ディスクを作成する。

```bash
# Docker環境に入る
docker run -it --rm --privileged ubuntu:24.04 bash

# QEMUのインストール
apt-get update && apt-get install -y qemu-system-x86 qemu-utils wget

# 仮想ディスクの作成（qcow2形式、2GB）
qemu-img create -f qcow2 disk.qcow2 2G

# Alpine LinuxのISOをダウンロード
wget https://dl-cdn.alpinelinux.org/alpine/v3.21/releases/x86_64/alpine-virt-3.21.3-x86_64.iso
```

ここで立ち止まって考えてほしい。`qemu-img create -f qcow2 disk.qcow2 2G` の一行で、仮想ディスクが作成された。AWS EC2でEBSボリュームを作成するとき、`aws ec2 create-volume --size 2` と実行するが、その裏側ではこれと同質の処理が（はるかに洗練された形で）行われている。

```bash
# QEMUで仮想マシンを起動（CPU 1コア、メモリ 512MB）
qemu-system-x86_64 \
  -m 512 \
  -smp 1 \
  -hda disk.qcow2 \
  -cdrom alpine-virt-3.21.3-x86_64.iso \
  -boot d \
  -nographic \
  -serial mon:stdio
```

各オプションの意味を確認しよう。

| オプション        | 意味                  | EC2での対応概念                |
| ----------------- | --------------------- | ------------------------------ |
| `-m 512`          | メモリ 512MB          | インスタンスタイプのメモリ仕様 |
| `-smp 1`          | CPUコア数 1           | vCPU数                         |
| `-hda disk.qcow2` | 仮想ディスク接続      | EBSボリュームのアタッチ        |
| `-cdrom ...`      | CDROMイメージ接続     | AMI（マシンイメージ）          |
| `-boot d`         | CDROMから起動         | 起動ディスクの指定             |
| `-nographic`      | GUIなし、シリアル出力 | SSHアクセス（GUIなし）         |

Alpine Linuxが起動したら、`root` でログインし、ネットワーク設定を行う。

```bash
# Alpine Linuxが起動したら、rootでログイン（パスワードなし）
# ネットワークインターフェースの確認
ip addr show

# DHCPでIPアドレスを取得
setup-interfaces
# デフォルト設定（eth0, dhcp）でEnterを押していく

# ネットワーク起動
ifup eth0
```

### 演習2：リソース制限を変更する

EC2ではインスタンスタイプを変更すればCPUやメモリのスペックが変わる。QEMUでは、起動オプションを変更する必要がある。

```bash
# メモリを1024MBに増やし、CPUを2コアにして起動
qemu-system-x86_64 \
  -m 1024 \
  -smp 2 \
  -hda disk.qcow2 \
  -boot c \
  -nographic \
  -serial mon:stdio
```

EC2の `t3.micro`（2 vCPU, 1 GiB）から `t3.small`（2 vCPU, 2 GiB）へのインスタンスタイプ変更は、コンソールで数クリック、あるいはCLIで一行。だがその裏では、ハイパーバイザレベルでメモリ割り当てが変更され、場合によっては別の物理ホストへの移動（マイグレーション）が発生する。

### 演習3：仮想ネットワークの構築

クラウドのVPC（Virtual Private Cloud）は、仮想ネットワークの抽象化だ。QEMUでは、TAPデバイスやブリッジを使ってネットワークを構築する。

```bash
# ホスト側でブリッジネットワークを作成
apt-get install -y bridge-utils iproute2

# ブリッジの作成
ip link add br0 type bridge
ip addr add 192.168.100.1/24 dev br0
ip link set br0 up

# TAPデバイスの作成（VM用の仮想NIC）
ip tuntap add tap0 mode tap
ip link set tap0 master br0
ip link set tap0 up

# QEMUに仮想NICを接続して起動
qemu-system-x86_64 \
  -m 512 \
  -smp 1 \
  -hda disk.qcow2 \
  -boot c \
  -nographic \
  -serial mon:stdio \
  -netdev tap,id=net0,ifname=tap0,script=no,downscript=no \
  -device virtio-net-pci,netdev=net0
```

ここで重要なのは、EC2インスタンスの「ENI（Elastic Network Interface）」が、概念的にはこのTAPデバイスの高度な抽象化であるという点だ。セキュリティグループのルールは、物理的にはiptablesやeBPF（Extended Berkeley Packet Filter）に相当するパケットフィルタリングで実現されている。VPCのサブネット分割は、VXLANなどのオーバーレイネットワーク技術で実現されている。

### この演習で何がわかるか

QEMUでの手動構築を通じて、以下のことが体感できるはずだ。

**第一に、クラウドが隠蔽している作業量の大きさ。** EC2インスタンスの起動は `aws ec2 run-instances` の一行だが、その裏側では仮想ディスクの作成、CPUとメモリの割り当て、ネットワークインターフェースの設定、ブートローダーの起動といった多数の工程が実行されている。

**第二に、抽象化の境界線。** QEMUの `-m 512` とEC2の `t3.micro` は、同じことを異なるレベルの抽象度で表現している。抽象化は複雑性を隠すが、消すわけではない。抽象の向こう側には、常に物理的な実体が存在する。

**第三に、「他人の計算機を借りる」という行為の本質。** QEMUで構築した仮想マシンは、自分のマシンの上で動いている。EC2インスタンスは、AWSのデータセンターにある物理サーバの上で動いている。この差は「場所」と「管理者」の違いであって、仮想化の原理そのものは同じだ。

ハンズオンの詳細な手順と自動セットアップスクリプトは、本リポジトリの `handson/cloud-history/01-without-cloud/` に用意してある。

---

## 6. まとめと次回予告

### この回のまとめ

第1回では、クラウドが「空気」になった現代において、私たちが見失いつつあるものを確認した。

**クラウド市場は巨大だ。** 2024年のIaaS市場は1,718億ドル。パブリッククラウド全体の支出は7,000億ドルを超える見込みだ。AWS、Azure、GCPの三強がIaaS市場の8割以上を占め、開発者の過半数がAWSを日常的に利用している。

**クラウドの本質は「他人の計算機を借りる」ことだ。** そしてこの発想は、1961年にJohn McCarthyが構想し、1960年代のメインフレームのタイムシェアリングで実践された。クラウドは、70年にわたる「計算資源の共有」の系譜の、最新の形態にすぎない。

**計算資源はCPU、メモリ、ストレージ、ネットワークの4要素で構成される。** クラウドは、これらの物理資源を抽象化し、API越しに提供している。`aws ec2 run-instances` の一行の裏側には、ハイパーバイザによる仮想マシン生成、仮想ネットワークの構築、ストレージの接続といった多数の工程が隠されている。

**隠蔽は悪ではないが、隠蔽を知らないのは問題だ。** 障害が起きたとき——そして障害は必ず起きる——抽象化の向こう側を想像できる人間と、できない人間の差は決定的だ。

冒頭の問いに、暫定的な答えを出そう。「クラウドが『空気』になった世界で、私たちは何を見失ったのか？」——計算資源の物理的な実体と、それを抽象化するレイヤーの存在を見失いつつある。だが、それは取り戻せるものだ。歴史を知り、抽象化の裏側を一度でも体験すれば、クラウドの景色は一変する。

### 次回予告

第2回では、メインフレームとタイムシェアリングの時代に遡る。1960年代、計算機は一台数億円の「聖域」だった。その聖域に、複数のユーザーが同時にアクセスする——この革命的なアイデアは、どのように生まれ、どのように実現されたのか。

MIT CTSS、Multics、IBM CP-67。これらの名前に聞き覚えはあるだろうか。なくても問題ない。だが、これらのシステムが達成したことは、あなたが毎日使っているクラウドの設計思想に直結している。

「複数のユーザーが一つの計算機を共有する」という発想は、どこから来たのか。次回、この問いを掘り下げる。

---

## 参考文献

- Gartner, "Gartner Says Worldwide IaaS Public Cloud Services Market Grew 22.5% in 2024", 2025年8月. <https://www.gartner.com/en/newsroom/press-releases/2025-08-06-gartner-says-worldwide-iaas-public-cloud-services-market-grew-22-point-5-percent-in-2024>
- Gartner, "Gartner Forecasts Worldwide Public Cloud End-User Spending to Total $723 Billion in 2025", 2024年11月. <https://www.gartner.com/en/newsroom/press-releases/2024-11-19-gartner-forecasts-worldwide-public-cloud-end-user-spending-to-total-723-billion-dollars-in-2025>
- Stack Overflow, "2024 Stack Overflow Developer Survey". <https://survey.stackoverflow.co/2024/technology>
- AWS, "Announcing Amazon Elastic Compute Cloud (Amazon EC2) - beta", 2006年8月. <https://aws.amazon.com/about-aws/whats-new/2006/08/24/announcing-amazon-elastic-compute-cloud-amazon-ec2---beta/>
- NIST, "The NIST Definition of Cloud Computing", SP 800-145, 2011年9月. <https://csrc.nist.gov/pubs/sp/800/145/final>
- IBM, "The IBM System/360". <https://www.ibm.com/history/system-360>
- IBM, "Time-sharing". <https://www.ibm.com/history/time-sharing>
- Fabrice Bellard, "QEMU, a Fast and Portable Dynamic Translator", USENIX Annual Technical Conference, 2005年. <https://www.usenix.org/legacy/event/usenix05/tech/freenix/full_papers/bellard/bellard.pdf>
